{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subdivisions': 'Saddle Ridge Estates', 'region_id': '1', 'for_sale': '1'}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "\n",
    "from urllib import parse\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "urls = [\"https://www.har.com/mapsearch/?subdivisions=NorthWest+Park+place&region_id=1&for_sale=1\",\n",
    "        \"https://www.har.com/mapsearch/?subdivisions=lismore+lake+estates&for_sale=1\",\n",
    "       \"https://www.har.com/mapsearch/?subdivisions=lakewood+oaks+estates&region_id=1&for_sale=1\",\n",
    "       \"https://www.har.com/mapsearch/?subdivisions=Riata+West&region_id=1&for_sale=1\",\n",
    "       \"https://www.har.com/mapsearch/?subdivisions=Saddle+Ridge+Estates&region_id=1&for_sale=1\"]\n",
    "\n",
    "\n",
    "# for url in urls:\n",
    "#     neighborhood = dict(parse.parse_qsl(parse.urlsplit(url).query))\n",
    "\n",
    "#     print(neighborhood)\n",
    "\n",
    "all_homes = []\n",
    "\n",
    "for index,url in enumerate(urls):\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    homes = soup.findAll('div', {\"class\": \"map_prop_item pointer\"})\n",
    "    neighborhood = dict(parse.parse_qsl(parse.urlsplit(url).query))\n",
    "    home_info = dict()\n",
    "    home_info['home_url'] = homes\n",
    "    home_info['neighborhood'] = neighborhood    \n",
    "    all_homes.append(home_info)\n",
    "    \n",
    "print(neighborhood)\n",
    "# allhomes_info = pd.DataFrame(all_homes)    \n",
    "# print(allhomes_info)\n",
    "\n",
    "\n",
    "#     neighborhoods.append(neighborhood)\n",
    "# print(neighborhoods)\n",
    "    \n",
    "# print(len(all_homes))\n",
    "    \n",
    "#     all_homes.append(neighborhood)\n",
    "# neighborhood = soup.findAll(\"a\", {\"data-criteria\":\"subdivisions\"})\n",
    "# print(neighborhood)\n",
    "\n",
    "# resultset = []\n",
    "\n",
    "# # for homes in all_homes:\n",
    "# for homes in all_homes:\n",
    "#     for home in homes['home_url']:\n",
    "#         home_details = dict()\n",
    "#         home_details['address'] = home.find('div', {'class': 'mpi_info'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').split('\\n')[0]\n",
    "#         home_details['price'] = home.find('div', {'class': 'price'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "#         home_details['days'] = home.find('span', {'class': 'bold'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "#         home_details['agent'] = home.find('div', {'class': 'capitalize bold'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "#         home_details['office'] = home.find('div', {'class': 'capitalize ellipse'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "#         home_details['neighborhood'] = homes['neighborhood']['subdivisions']\n",
    "#         resultset.append(home_details)\n",
    "        \n",
    "\n",
    "# info = pd.DataFrame(resultset)\n",
    "# print(info)\n",
    "\n",
    "                \n",
    "# with open('homes3.csv', 'w+',newline='') as csvFile:\n",
    "#     writer = csv.writer(csvFile)\n",
    "#     writer.writerow(['Address', 'Price', 'Days on Market', 'Agent', 'Office', 'Neighborhood'])\n",
    "#     for home in resultset:\n",
    "#         writer.writerow([home['address'], home['price'],home['days'], home['agent'], home['office'], home['neighborhood']])\n",
    "                                                                                \n",
    "                                                                                \n",
    "# end = time.time()\n",
    "# print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def har_homes():\n",
    "    urls = [\"https://www.har.com/mapsearch/?subdivisions=NorthWest+Park+place&region_id=1&for_sale=1\",\n",
    "            \"https://www.har.com/mapsearch/?subdivisions=lismore+lake+estates&for_sale=1\",\n",
    "           \"https://www.har.com/mapsearch/?subdivisions=lakewood+oaks+estates&region_id=1&for_sale=1\",\n",
    "           \"https://www.har.com/mapsearch/?subdivisions=Riata+West&region_id=1&for_sale=1\",\n",
    "           \"https://www.har.com/mapsearch/?subdivisions=Saddle+Ridge+Estates&region_id=1&for_sale=1\"]\n",
    "\n",
    "    all_homes = []\n",
    "\n",
    "    for index,url in enumerate(urls):\n",
    "        html = requests.get(url).text\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        homes = soup.findAll('div', {\"class\": \"map_prop_item pointer\"})\n",
    "        neighborhood = dict(parse.parse_qsl(parse.urlsplit(url).query))\n",
    "        home_info = dict()\n",
    "        home_info['home_url'] = homes\n",
    "        home_info['neighborhood'] = neighborhood    \n",
    "        all_homes.append(home_info)\n",
    "\n",
    "    resultset = []\n",
    "\n",
    "    for homes in all_homes:\n",
    "        for home in homes['home_url']:\n",
    "            home_details = dict()\n",
    "            home_details['address'] = home.find('div', {'class': 'mpi_info'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').split('\\n')[0]\n",
    "            home_details['price'] = home.find('div', {'class': 'price'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "            home_details['days'] = home.find('span', {'class': 'bold'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "            home_details['agent'] = home.find('div', {'class': 'capitalize bold'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "            home_details['office'] = home.find('div', {'class': 'capitalize ellipse'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "            home_details['neighborhood'] = homes['neighborhood']['subdivisions']\n",
    "            resultset.append(home_details)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    \n",
    "#     with open('homes3.csv', 'w+',newline='') as csvFile:\n",
    "#     writer = csv.writer(csvFile)\n",
    "#     writer.writerow(['Address', 'Price', 'Days_on_Market', 'Agent', 'Office', 'Neighborhood'])\n",
    "#     for home in resultset:\n",
    "#         writer.writerow([home['address'], home['price'],home['days'], home['agent'], home['office'], home['neighborhood']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          address              agent days  \\\n",
      "0            10110 Fallmont Court    Alexander Ebner    8   \n",
      "1        12035 Lismore Lake Drive    Mitchell Haynes   62   \n",
      "2        11843 Lismore Lake Drive       Edward Roehm   52   \n",
      "3        12151 Lismore Lake Drive    Jennifer Ciulla   82   \n",
      "4              13718 Pegasus Road           Young Le   61   \n",
      "5           13614 Gainesway Drive  Stephanie Martens   28   \n",
      "6              13511 Pegasus Road    Teresa Goralski   67   \n",
      "7          13106 Springmint Court       Evan Compean  153   \n",
      "8   13802 Copeland Oaks Boulevard   Carolyn Williams   11   \n",
      "9   13518 Copeland Oaks Boulevard   Anthony Levinson   14   \n",
      "10           14011 Pegasus Circle      Mark Raisbeck  251   \n",
      "11             13618 Pegasus Road  Stephanie Martens   32   \n",
      "12             13614 Pegasus Road    Ronnie Matthews   33   \n",
      "13        11207 Barker West Drive    Frank Monacelli  167   \n",
      "14        10923 Barker View Drive     Jimmy Franklin   48   \n",
      "15       17951 Branch Creek Drive     Candice Harris   43   \n",
      "16     18030 Riata Crossing Drive      Cesar Ramirez   80   \n",
      "17        16810 Saddle Ridge Pass   William Phillips   54   \n",
      "18        17203 Saddle Ridge Pass       Clint Nabors  169   \n",
      "19        16703 Saddle Ridge Pass       Mark Bonning   27   \n",
      "\n",
      "             neighborhood                                             office  \\\n",
      "0    NorthWest Park place  Coldwell Banker United, Realtors - Bellaire Of...   \n",
      "1    lismore lake estates                                          BuyBroker   \n",
      "2    lismore lake estates   Better Homes and Gardens Real Estate Gary Greene   \n",
      "3    lismore lake estates                             RE/MAX Fine Properties   \n",
      "4   lakewood oaks estates                          Texas Independence Realty   \n",
      "5   lakewood oaks estates   Better Homes and Gardens Real Estate Gary Greene   \n",
      "6   lakewood oaks estates   Better Homes and Gardens Real Estate Gary Greene   \n",
      "7   lakewood oaks estates                        Champions Real Estate Group   \n",
      "8   lakewood oaks estates                           Keller Williams Platinum   \n",
      "9   lakewood oaks estates  Better Homes and Gardens Real Estate Gary Gree...   \n",
      "10  lakewood oaks estates                            RE/MAX Elite Properties   \n",
      "11  lakewood oaks estates   Better Homes and Gardens Real Estate Gary Greene   \n",
      "12  lakewood oaks estates                                     RE/MAX Legends   \n",
      "13             Riata West                                    Nino Properties   \n",
      "14             Riata West                                     eXp Realty LLC   \n",
      "15             Riata West                                   CA Modern Realty   \n",
      "16             Riata West                                         Vylla Home   \n",
      "17   Saddle Ridge Estates                           John Daugherty, Realtors   \n",
      "18   Saddle Ridge Estates   Better Homes and Gardens Real Estate Gary Greene   \n",
      "19   Saddle Ridge Estates                                Bonning Real Estate   \n",
      "\n",
      "       price  \n",
      "0     170000  \n",
      "1     349900  \n",
      "2     345000  \n",
      "3     329900  \n",
      "4     519000  \n",
      "5     500000  \n",
      "6     489500  \n",
      "7     485000  \n",
      "8     484900  \n",
      "9     470000  \n",
      "10    460000  \n",
      "11    450000  \n",
      "12    415000  \n",
      "13    279488  \n",
      "14    219000  \n",
      "15    198500  \n",
      "16    189900  \n",
      "17   4999500  \n",
      "18   2150000  \n",
      "19   1258000  \n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "\n",
    "from urllib import parse\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "urls = [\"https://www.har.com/mapsearch/?subdivisions=NorthWest+Park+place&region_id=1&for_sale=1\",\n",
    "        \"https://www.har.com/mapsearch/?subdivisions=lismore+lake+estates&for_sale=1\",\n",
    "       \"https://www.har.com/mapsearch/?subdivisions=lakewood+oaks+estates&region_id=1&for_sale=1\",\n",
    "       \"https://www.har.com/mapsearch/?subdivisions=Riata+West&region_id=1&for_sale=1\",\n",
    "       \"https://www.har.com/mapsearch/?subdivisions=Saddle+Ridge+Estates&region_id=1&for_sale=1\"]\n",
    "\n",
    "all_homes = []\n",
    "\n",
    "for index,url in enumerate(urls):\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    homes = soup.findAll('div', {\"class\": \"map_prop_item pointer\"})\n",
    "    neighborhood = dict(parse.parse_qsl(parse.urlsplit(url).query))\n",
    "    home_info = dict()\n",
    "    home_info['home_url'] = homes\n",
    "    home_info['neighborhood'] = neighborhood    \n",
    "    all_homes.append(home_info)\n",
    "\n",
    "resultset = []\n",
    "\n",
    "# for homes in all_homes:\n",
    "for homes in all_homes:\n",
    "    for home in homes['home_url']:\n",
    "        home_details = dict()\n",
    "        home_details['address'] = home.find('div', {'class': 'mpi_info'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').split('\\n')[0]\n",
    "        home_details['price'] = home.find('div', {'class': 'price'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').replace(',','').replace('$','')\n",
    "        home_details['days'] = home.find('span', {'class': 'bold'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "        home_details['agent'] = home.find('div', {'class': 'capitalize bold'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "        home_details['office'] = home.find('div', {'class': 'capitalize ellipse'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "        home_details['neighborhood'] = homes['neighborhood']['subdivisions']\n",
    "        resultset.append(home_details)                                   \n",
    "                                           \n",
    "info = pd.DataFrame(resultset)\n",
    "print(info)\n",
    "                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
