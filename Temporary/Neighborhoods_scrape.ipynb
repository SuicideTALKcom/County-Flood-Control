{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1456fb0a7788>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mhar_homes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# def threader(job_func):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-1456fb0a7788>\u001b[0m in \u001b[0;36mhar_homes\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html.parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#get the neighborhood info as text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mhood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'h1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'uppercase reguler font31 titlef5'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;31m#create a pattern to extract the neighborhood name clean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhood\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1805\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m         raise AttributeError(\n\u001b[0;32m-> 1807\u001b[0;31m             \u001b[0;34m\"ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m         )\n",
      "\u001b[0;31mAttributeError\u001b[0m: ResultSet object has no attribute 'text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "from urllib import parse\n",
    "import re \n",
    "import schedule\n",
    "import threading \n",
    "\n",
    "def har_homes():\n",
    "    urls = [\"https://www.har.com/riverwood-estates/homes-for-sale/2377?sort=listdate+desc\",\n",
    "            \"https://www.har.com/forest-shadows/homes-for-sale/4585?sort=listdate+desc\",\n",
    "           \"https://www.har.com/aldine-estates/homes-for-sale/1917?sort=listdate+desc\",\n",
    "           \"https://www.har.com/greenbranch/homes-for-sale/1921?sort=listdate+desc\",\n",
    "           \"https://www.har.com/castlewood/homes-for-sale/2078?sort=listdate+desc\",\n",
    "           \"https://www.har.com/bamwood-terrace/homes-for-sale/3693?sort=listdate+desc\"]\n",
    "\n",
    "    all_homes = []\n",
    "\n",
    "    #iterate through the urls\n",
    "    for index,url in enumerate(urls):\n",
    "        #get the request\n",
    "        html = requests.get(url).text\n",
    "        #create a beautifulsoup object and parse \n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        #get the neighborhood info as text\n",
    "        hood = soup.find_all('h1', attrs= {'class':'uppercase reguler font31 titlef5'}).text\n",
    "        #create a pattern to extract the neighborhood name clean\n",
    "        pattern = re.compile(hood)\n",
    "        new_pattern = pattern.findall('homes  for sale')\n",
    "        drop = re.sub(new_pattern,\"\", hood)\n",
    "        #element that contains all detail info\n",
    "        homes = soup.find_all('div', {\"id\": \"search_results\"}).text.strip().encode(\"utf-8\")\n",
    "\n",
    "        #create a dictionary and append the url results with neighborhoods\n",
    "        home_info = dict()\n",
    "        home_info['home_url'] = homes\n",
    "        home_info ['neighborhood'] = drop\n",
    "        all_homes.append(home_info)\n",
    "\n",
    "    resultset = []\n",
    "\n",
    "        #iterate through the search results from the urls   \n",
    "    for homes in all_homes:\n",
    "        for home in homes['home_url']:\n",
    "            home_details = dict()\n",
    "            #information contained under one tag\n",
    "            all_info = home.find_all('div', class_= 'mpi_info')\n",
    "            #iterate through the double values that are returned and attach the value by index to the dictionary\n",
    "            for info in all_info:\n",
    "                home_details ['address'] = info.find('span', class_= 'bold').contents[0].text\n",
    "                home_details ['days'] = info.find('span', class_= 'bold').contents[1].text\n",
    "                home_details ['agent'] = info.find('a').find('title')['bold'].contents[0].text\n",
    "                home_details ['office'] = info.find('a').find('title')['bold'].contents[1].text\n",
    "            #identify and return price\n",
    "            home_details ['price']= home.find('div','price').text.replace(',','').replace('$','')\n",
    "            home_details ['neighborhood'] = home_info['neighborhood']\n",
    "            resultset.append(home_details)\n",
    "        return resultset\n",
    "\n",
    "\n",
    "                \n",
    " \n",
    "har_homes()               \n",
    "                \n",
    "# def threader(job_func):\n",
    "#     job_thread = threading.Thread(target=job_func)\n",
    "#     job_thread.start()\n",
    "\n",
    "# schedule.every().seconds.do(threader, har_homes)\n",
    "\n",
    "# def main():    \n",
    "#     schedule.run_pending()\n",
    "#     time.sleep(1)                \n",
    "\n",
    "        \n",
    "#         home_info['home_url'] = homes\n",
    "#         home_info['neighborhood'] = neighborhood\n",
    "#         all_homes.append(home_info)\n",
    "\n",
    "#         print(home_info['home_url'])\n",
    "\n",
    "\n",
    "\n",
    "# for homes in all_homes:\n",
    "#     for home in homes['home_url']:\n",
    "#         home_details = dict()\n",
    "#         home_details['address'] = home.find('a', {'class': 'address'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').split('\\n')[0]\n",
    "#         home_details['price'] = home.find('div', {'class': 'price'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').replace(',','').replace('$','')\n",
    "#         home_details['days'] = home.find('span', {'class': 'bold'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "#         home_details['agent'] = home.find('div', {'class': 'capitalize bold'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "#         home_details['office'] = home.find('div', {'class': 'capitalize ellipse'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "#         home_details['neighborhood'] = homes_info['neighborhood']\n",
    "#         resultset.append(home_details)\n",
    "#     return resultset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
