{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'price': '199000'}\n",
      "[{'neighborhood': 'forest shadows', 'address': '21807 Forest Glade Drive', 'city': 'Humble', 'state': 'TX', 'zip': '77338', 'days': '8', 'agent': 'Jodi Manfred', 'office': 'JLA Realty'}, {'neighborhood': 'forest shadows', 'address': '4706 Broadmark Lane', 'city': 'Humble', 'state': 'TX', 'zip': '77338', 'days': '50', 'agent': 'Cellina Stokes', 'office': 'Crowne Realty'}, {'neighborhood': 'forest shadows', 'address': '4602 Fieldwick Lane', 'city': 'Humble', 'state': 'TX', 'zip': '77338', 'days': '64', 'agent': 'Michael Thiltgen', 'office': 'Greenbriar Real Estate Service'}, {'neighborhood': 'forest shadows', 'address': '21802 Pine Cone Drive', 'city': 'Humble', 'state': 'TX', 'zip': '77338', 'days': '65', 'agent': 'Katherine Ware', 'office': 'Irie Properties, LLC'}, {'neighborhood': 'forest shadows', 'address': '4503 Clairfield Lane', 'city': 'Humble', 'state': 'TX', 'zip': '77338', 'days': '106', 'agent': 'Rick Raymor', 'office': 'RE/MAX Professional Group'}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "from urllib import parse\n",
    "import re \n",
    "from datetime import datetime\n",
    "import schedule\n",
    "import threading \n",
    "from task import homes_comparison\n",
    "import csv\n",
    "import itertools\n",
    "import ast\n",
    "\n",
    "urls = [\"https://www.har.com/forest-shadows/homes-for-sale/4585?sort=listdate+desc\"]\n",
    "\n",
    "all_homes = []\n",
    "\n",
    "for url in urls:\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    price, homes = itertools.tee(soup.find_all(\"div\", class_=\"prop_list\"))\n",
    "    neighborhood = url.split('/')[3].replace('-',' ')\n",
    "\n",
    "    for item in homes: \n",
    "        try:\n",
    "            for info in item.find_all(class_= 'mpi_info'):\n",
    "                full_address = info.find_all('a', class_= 'address')[0].text\n",
    "                split_address = full_address.split(',')\n",
    "                use_split_address = split_address[0].strip()\n",
    "                use_split_city = split_address[1].strip()\n",
    "                state_zip = split_address[2].split(' ')\n",
    "                use_state = state_zip[1].strip()\n",
    "                use_zip = state_zip[2].strip()\n",
    "                use_days = info.find_all('span', class_= 'bold')[1].text\n",
    "                use_agent = info.find_all('a', class_='bold')[0].text \n",
    "                use_office = info.find_all('a', class_= 'bold')[1].text.strip()\n",
    "                \n",
    "                home_info=  {\n",
    "                    \"neighborhood\": neighborhood,\n",
    "                    \"address\": use_split_address,\n",
    "                    \"city\": use_split_city,\n",
    "                    \"state\": use_state,\n",
    "                    \"zip\": use_zip,\n",
    "                    \"days\": use_days,\n",
    "                    \"agent\": use_agent,\n",
    "                    \"office\": use_office}\n",
    "                all_homes.append(home_info)\n",
    "                \n",
    "            \n",
    "        except:\n",
    "            print(\"No results given for \" + url)\n",
    "            continue\n",
    " \n",
    "    \n",
    "\n",
    "    for p in price:\n",
    "        try:\n",
    "            for img in p.find_all(class_='price'):\n",
    "                price_list = img.text.replace('$', '').replace(',','').strip('][')\n",
    "                new_price = price_list[2:8].strip().split('/n')\n",
    "                for new in new_price:\n",
    "                    final_price = {\n",
    "                        \"price\": new\n",
    "                        }\n",
    "                print(final_price)\n",
    "                \n",
    "                final_price.append(all_homes)\n",
    "# #                 final_price = ast.literal_eval(price_list)\n",
    "#                 print(final_price)\n",
    "#                 type(final_price)\n",
    "#                 print(img.text)\n",
    "#                 price_list= [i for i in img.find_all(class_= \"price\")[0]]\n",
    "# home_price = img.find_all('div', class_= \"price\")[0].text.replace('\\n','').replace(',','').replace('$','')\n",
    "#                 print(price_list)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    \n",
    "    \n",
    "print(all_homes)\n",
    "# print(final_price)\n",
    "# type(final_price)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     with open('scraped_homes.csv', 'w', encoding='utf8', newline='') as output_file:\n",
    "#         fc = csv.DictWriter(output_file, \n",
    "#                             fieldnames=all_homes[1:5].keys(),\n",
    "\n",
    "#                            )\n",
    "#         fc.writeheader()\n",
    "#         fc.writerows(all_homes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
