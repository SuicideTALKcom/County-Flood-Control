{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       address              agent days           neighborhood  \\\n",
      "0     9827 Golden Prairie Lane   Isaias Contreras    6   NorthWest Park place   \n",
      "1         6035 Cascadera Drive      Phuong Nguyen   35   NorthWest Park place   \n",
      "2         10110 Fallmont Court    Alexander Ebner    8   NorthWest Park place   \n",
      "3           5822 Wickover Lane   Ruben Villarreal    5   NorthWest Park place   \n",
      "4     12035 Lismore Lake Drive    Mitchell Haynes   54   lismore lake estates   \n",
      "5     12151 Lismore Lake Drive    Jennifer Ciulla   43   lismore lake estates   \n",
      "6        11918 Galentine Point      Amjad Mushtaq  174   lismore lake estates   \n",
      "7       13910 Springmint Drive         John Prell    5  lakewood oaks estates   \n",
      "8           13718 Pegasus Road           Young Le   22  lakewood oaks estates   \n",
      "9           13511 Pegasus Road    Teresa Goralski   28  lakewood oaks estates   \n",
      "10      13106 Springmint Court       Evan Compean  114  lakewood oaks estates   \n",
      "11        14011 Pegasus Circle      Mark Raisbeck  212  lakewood oaks estates   \n",
      "12          13618 Pegasus Road  Stephanie Martens    8  lakewood oaks estates   \n",
      "13     11207 Barker West Drive   Darrell Anderson  128             Riata West   \n",
      "14     10923 Barker View Drive     Jimmy Franklin   17             Riata West   \n",
      "15     10902 Barker View Drive     Claudia Ocadiz    2             Riata West   \n",
      "16    17923 Cypress Side Drive     Cameron Namazi   27             Riata West   \n",
      "17    17951 Branch Creek Drive     Candice Harris   11             Riata West   \n",
      "18  18030 Riata Crossing Drive      Cesar Ramirez   80             Riata West   \n",
      "19     10915 Barker View Drive      Alian Johnson    4             Riata West   \n",
      "20    11115 Riata Canyon Drive    Allison Fontana    1             Riata West   \n",
      "21     16810 Saddle Ridge Pass   William Phillips   15   Saddle Ridge Estates   \n",
      "22     17203 Saddle Ridge Pass       Clint Nabors  163   Saddle Ridge Estates   \n",
      "23     16510 Saddle Ridge Pass      Sharon Vaughn  134   Saddle Ridge Estates   \n",
      "24     16703 Saddle Ridge Pass       Mark Bonning   27   Saddle Ridge Estates   \n",
      "\n",
      "                                               office        price  \n",
      "0                           Keller Williams Signature    $ 195,000  \n",
      "1                                BlueRoof Real Estate    $ 195,000  \n",
      "2   Coldwell Banker United, Realtors - Bellaire Of...    $ 170,000  \n",
      "3                                    RE/MAX Integrity    $ 169,990  \n",
      "4                                           BuyBroker    $ 349,900  \n",
      "5                              RE/MAX Fine Properties    $ 329,900  \n",
      "6                                          Fast Homes    $ 289,900  \n",
      "7                                    Creekview Realty    $ 615,000  \n",
      "8                           Texas Independence Realty    $ 529,000  \n",
      "9    Better Homes and Gardens Real Estate Gary Greene    $ 499,500  \n",
      "10                        Champions Real Estate Group    $ 499,500  \n",
      "11                            RE/MAX Elite Properties    $ 465,000  \n",
      "12                                  BHGRE Gary Greene    $ 450,000  \n",
      "13                                    Nino Properties    $ 298,799  \n",
      "14                                     eXp Realty LLC    $ 225,000  \n",
      "15                              Blake Richards Realty    $ 224,900  \n",
      "16                                      Summit Realty    $ 224,500  \n",
      "17                                   CA Modern Realty    $ 198,500  \n",
      "18                                         Vylla Home    $ 189,900  \n",
      "19                        Champions Real Estate Group    $ 179,999  \n",
      "20                                Texas Realty Select    $ 179,900  \n",
      "21                           John Daugherty, Realtors  $ 4,999,500  \n",
      "22   Better Homes and Gardens Real Estate Gary Greene  $ 2,150,000  \n",
      "23                                    Zuri Properties  $ 1,997,000  \n",
      "24                                Bonning Real Estate  $ 1,258,000  \n",
      "3.0576071739196777\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "\n",
    "from urllib import parse\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "urls = [\"https://www.har.com/mapsearch/?subdivisions=NorthWest+Park+place&region_id=1&for_sale=1\",\n",
    "        \"https://www.har.com/mapsearch/?subdivisions=lismore+lake+estates&for_sale=1\",\n",
    "       \"https://www.har.com/mapsearch/?subdivisions=lakewood+oaks+estates&region_id=1&for_sale=1\",\n",
    "       \"https://www.har.com/mapsearch/?subdivisions=Riata+West&region_id=1&for_sale=1\",\n",
    "       \"https://www.har.com/mapsearch/?subdivisions=Saddle+Ridge+Estates&region_id=1&for_sale=1\"]\n",
    "\n",
    "\n",
    "# for url in urls:\n",
    "#     neighborhood = dict(parse.parse_qsl(parse.urlsplit(url).query))\n",
    "\n",
    "#     print(neighborhood)\n",
    "\n",
    "all_homes = []\n",
    "\n",
    "for index,url in enumerate(urls):\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    homes = soup.findAll('div', {\"class\": \"map_prop_item pointer\"})\n",
    "    neighborhood = dict(parse.parse_qsl(parse.urlsplit(url).query))\n",
    "    home_info = dict()\n",
    "    home_info['home_url'] = homes\n",
    "    home_info['neighborhood'] = neighborhood    \n",
    "    all_homes.append(home_info)\n",
    "    \n",
    "\n",
    "# allhomes_info = pd.DataFrame(all_homes)    \n",
    "# print(allhomes_info)\n",
    "\n",
    "\n",
    "#     neighborhoods.append(neighborhood)\n",
    "# print(neighborhoods)\n",
    "    \n",
    "# print(len(all_homes))\n",
    "    \n",
    "#     all_homes.append(neighborhood)\n",
    "# neighborhood = soup.findAll(\"a\", {\"data-criteria\":\"subdivisions\"})\n",
    "# print(neighborhood)\n",
    "\n",
    "resultset = []\n",
    "\n",
    "# for homes in all_homes:\n",
    "for homes in all_homes:\n",
    "    for home in homes['home_url']:\n",
    "        home_details = dict()\n",
    "        home_details['address'] = home.find('div', {'class': 'mpi_info'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').split('\\n')[0]\n",
    "        home_details['price'] = home.find('div', {'class': 'price'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "        home_details['days'] = home.find('span', {'class': 'bold'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "        home_details['agent'] = home.find('div', {'class': 'capitalize bold'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "        home_details['office'] = home.find('div', {'class': 'capitalize ellipse'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "        home_details['neighborhood'] = homes['neighborhood']['subdivisions']\n",
    "        resultset.append(home_details)\n",
    "        \n",
    "\n",
    "info = pd.DataFrame(resultset)\n",
    "print(info)\n",
    "\n",
    "                \n",
    "# with open('homes3.csv', 'w+',newline='') as csvFile:\n",
    "#     writer = csv.writer(csvFile)\n",
    "#     writer.writerow(['Address', 'Price', 'Days on Market', 'Agent', 'Office', 'Neighborhood'])\n",
    "#     for home in resultset:\n",
    "#         writer.writerow([home['address'], home['price'],home['days'], home['agent'], home['office'], home['neighborhood']])\n",
    "                                                                                \n",
    "                                                                                \n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-61d30c48d0ed>, line 40)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-61d30c48d0ed>\"\u001b[0;36m, line \u001b[0;32m40\u001b[0m\n\u001b[0;31m    return(resultset)\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def har_homes():\n",
    "    urls = [\"https://www.har.com/mapsearch/?subdivisions=NorthWest+Park+place&region_id=1&for_sale=1\",\n",
    "            \"https://www.har.com/mapsearch/?subdivisions=lismore+lake+estates&for_sale=1\",\n",
    "           \"https://www.har.com/mapsearch/?subdivisions=lakewood+oaks+estates&region_id=1&for_sale=1\",\n",
    "           \"https://www.har.com/mapsearch/?subdivisions=Riata+West&region_id=1&for_sale=1\",\n",
    "           \"https://www.har.com/mapsearch/?subdivisions=Saddle+Ridge+Estates&region_id=1&for_sale=1\"]\n",
    "\n",
    "    all_homes = []\n",
    "\n",
    "    for index,url in enumerate(urls):\n",
    "        html = requests.get(url).text\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        homes = soup.findAll('div', {\"class\": \"map_prop_item pointer\"})\n",
    "        neighborhood = dict(parse.parse_qsl(parse.urlsplit(url).query))\n",
    "        home_info = dict()\n",
    "        home_info['home_url'] = homes\n",
    "        home_info['neighborhood'] = neighborhood    \n",
    "        all_homes.append(home_info)\n",
    "\n",
    "    resultset = []\n",
    "\n",
    "    for homes in all_homes:\n",
    "        for home in homes['home_url']:\n",
    "            home_details = dict()\n",
    "            home_details['address'] = home.find('div', {'class': 'mpi_info'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').split('\\n')[0]\n",
    "            home_details['price'] = home.find('div', {'class': 'price'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "            home_details['days'] = home.find('span', {'class': 'bold'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "            home_details['agent'] = home.find('div', {'class': 'capitalize bold'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "            home_details['office'] = home.find('div', {'class': 'capitalize ellipse'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "            home_details['neighborhood'] = homes['neighborhood']['subdivisions']\n",
    "            resultset.append(home_details)\n",
    "    \n",
    "    \n",
    "    with open('homes3.csv', 'w+',newline='') as csvFile:\n",
    "        writer = csv.writer(csvFile)\n",
    "        writer.writerow(['Address', 'Price', 'Days on Market', 'Agent', 'Office', 'Neighborhood'])\n",
    "    for home in resultset:\n",
    "        writer.writerow([home['address'], home['price'],home['days'], home['agent'], home['office'], home['neighborhood']\n",
    "\n",
    "return(resultset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
