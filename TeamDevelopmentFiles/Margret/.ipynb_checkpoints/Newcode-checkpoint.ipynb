{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "\n",
    "from urllib import parse\n",
    "\n",
    "urls = [\"https://www.har.com/mapsearch/?subdivisions=NorthWest+Park+place&region_id=1&for_sale=1\",\n",
    "        \"https://www.har.com/mapsearch/?subdivisions=lismore+lake+estates&for_sale=1\",\n",
    "       \"https://www.har.com/mapsearch/?subdivisions=lakewood+oaks+estates&region_id=1&for_sale=1\",\n",
    "       \"https://www.har.com/mapsearch/?subdivisions=Riata+West&region_id=1&for_sale=1\",\n",
    "       \"https://www.har.com/mapsearch/?subdivisions=Saddle+Ridge+Estates&region_id=1&for_sale=1\"]\n",
    "\n",
    "\n",
    "# for url in urls:\n",
    "#     neighborhood = dict(parse.parse_qsl(parse.urlsplit(url).query))\n",
    "\n",
    "#     print(neighborhood)\n",
    "\n",
    "all_homes = []\n",
    "\n",
    "for index,url in enumerate(urls):\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    homes = soup.findAll('div', {\"class\": \"map_prop_item pointer\"})\n",
    "    neighborhood = dict(parse.parse_qsl(parse.urlsplit(url).query))\n",
    "    home_info = dict()\n",
    "    home_info['home_url'] = homes\n",
    "    home_info['neighborhood'] = neighborhood    \n",
    "    all_homes.append(home_info)\n",
    "\n",
    "\n",
    "#     neighborhoods.append(neighborhood)\n",
    "    \n",
    "# print(neighborhoods)\n",
    "    \n",
    "print(len(all_homes))\n",
    "    \n",
    "#     all_homes.append(neighborhood)\n",
    "# neighborhood = soup.findAll(\"a\", {\"data-criteria\":\"subdivisions\"})\n",
    "# print(neighborhood)\n",
    "\n",
    "resultset = []\n",
    "\n",
    "# for homes in all_homes:\n",
    "for homes in all_homes:\n",
    "    home_details = dict()\n",
    "    for home in homes['home_url']:\n",
    "        home_details['neighborhood'] = homes['neighborhood']['subdivisions']\n",
    "        home_details['address'] = home.find('div', {'class': 'mpi_info'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "        home_details['price'] = home.find('div', {'class': 'price'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "        home_details['days'] = home.find('span', {'class': 'bold'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "        home_details['agent'] = home.find('div', {'class': 'capitalize bold'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "        home_details['office'] = home.find('div', {'class': 'capitalize ellipse'}).text.strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ').strip('\\n\\r\\t\": ')\n",
    "        resultset.append(home_details)\n",
    "        \n",
    "#     print(home_details)\n",
    "                \n",
    "with open('homes3.csv', 'w+',newline='') as csvFile:\n",
    "    writer = csv.writer(csvFile)\n",
    "    writer.writerow(['Address', 'Price', 'Days on Market', 'Agent', 'Office', 'Neighborhood'])\n",
    "    for home in resultset:\n",
    "        writer.writerow([home['address'], home['price'],home['days'], home['agent'], home['office'], home['neighborhood']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
